# fpc-llama.cpp

Freepascal bindings for Llama.cpp

Derived from https://github.com/Kagamma/llama-pas, but updated to work with llama.cpp, commit 82e4f64578dc3db40185e6b91195e73c9e995952 Tue Dec 12 20:04:10 2023 +0100

Also provided is llama-cli, an example application to do basic inference of gguf models. Build it with:

    lazbuild llama_cli.lpi

For a complete GUI application using Llama.cpp and fpc-llama, see Neurochat at https://github.com/ortegaalfredo/neurochat 

Tested with fpc 3.2.2, Lazarus 3.0.0.

